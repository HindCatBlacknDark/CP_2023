{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2f23d31",
   "metadata": {},
   "source": [
    "## **Import packages and data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75894c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------- Download Data -----------------\n",
    "import requests\n",
    "import os\n",
    "import sys \n",
    "\n",
    "#La Manno et al. 2020, Developing Mouse Brain data\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "def download_file(doi,ext):\n",
    "\turl = 'https://api.datacite.org/dois/'+doi+'/media'\n",
    "\tr = requests.get(url).json()\n",
    "\tnetcdf_url = r['data'][0]['attributes']['url']\n",
    "\tr = requests.get(netcdf_url,stream=True)\n",
    "\t#Set file name\n",
    "\tfname = doi.split('/')[-1]+ext\n",
    "\t#Download file with progress bar\n",
    "\tif r.status_code == 403:\n",
    "\t\tprint(\"File Unavailable\")\n",
    "\tif 'content-length' not in r.headers:\n",
    "\t\tprint(\"Did not get file\")\n",
    "\telse:\n",
    "\t\twith open(fname, 'wb') as f:\n",
    "\t\t\ttotal_length = int(r.headers.get('content-length'))\n",
    "\t\t\tpbar = tnrange(int(total_length/1024), unit=\"B\")\n",
    "\t\t\tfor chunk in r.iter_content(chunk_size=1024):\n",
    "\t\t\t\tif chunk:\n",
    "\t\t\t\t\tpbar.update()\n",
    "\t\t\t\t\tf.write(chunk)\n",
    "\t\treturn fname\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c75294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfa46d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchari/.local/lib/python3.7/site-packages/ipykernel_launcher.py:23: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a321082aab354777b59269a07917280b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147369 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0924ba09bc044c68871079f242aec2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f90b656f6f4db2acab9fec270792a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/831 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dev_all_hvg.mtx\n",
    "download_file('10.22002/D1.2043','.gz')\n",
    "\n",
    "#dev_all_raw.mtx\n",
    "download_file('10.22002/D1.2044','.gz')\n",
    "\n",
    "#lamannometadata.csv\n",
    "download_file('10.22002/D1.2045','.gz')\n",
    "\n",
    "os.system(\"gunzip *.gz\")\n",
    "\n",
    "os.system(\"mv D1.2043 dev_all_hvg.mtx\")\n",
    "os.system(\"mv D1.2044 dev_all_raw.mtx\")\n",
    "os.system(\"mv D1.2045 metadata.csv\")\n",
    "\n",
    "\n",
    "# os.system(\"pip3 install --quiet torch --no-cache-dir\")\n",
    "# os.system(\"pip3 install --quiet anndata --no-cache-dir\")\n",
    "# os.system(\"pip3 install --quiet matplotlib --no-cache-dir\")\n",
    "# os.system(\"pip3 install --quiet scikit-learn --no-cache-dir\")\n",
    "# os.system(\"pip3 install --quiet torchsummary --no-cache-dir\")\n",
    "# os.system(\"pip install --quiet scanpy==1.6.0 --no-cache-dir\")\n",
    "# #pip3 install --quiet umap-learn --no-cache-dir\n",
    "# os.system(\"pip3 install --quiet scvi-tools --no-cache-dir\")\n",
    "\n",
    "\n",
    "#os.system(\"git clone https://github.com/pachterlab/CP_2023.git\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2865dd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"wget --quiet https://storage.googleapis.com/linnarsson-lab-loom/dev_all.loom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05cd2ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/pytorch_lightning/utilities/warnings.py:54: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "  \"pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6\"\n",
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "  return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import anndata \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import loompy as lp\n",
    "# import visualizations as vis\n",
    "# import tools as tl\n",
    "import random\n",
    "import scvi\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis, NearestNeighbors\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import scale\n",
    "import torch\n",
    "import time\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import umap\n",
    "from scipy import stats\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5252147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(292495, 1999)\n",
      "(292495, 1999)\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "plt.rcParams['axes.linewidth'] = 0.1\n",
    "\n",
    "state = 42\n",
    "ndims = 2\n",
    "\n",
    "data_path = './'\n",
    "\n",
    "pcs = 50\n",
    "pcs2 = 100\n",
    "hpfs = 96\n",
    "hpfs2 = 30\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "count_mat = sio.mmread(data_path+'/dev_all_hvg.mtx')\n",
    "count_mat = count_mat.todense()\n",
    "\n",
    "print(count_mat.shape)\n",
    "\n",
    "rawcount_mat = sio.mmread(data_path+'/dev_all_raw.mtx')\n",
    "rawcount_mat  = rawcount_mat.todense()\n",
    "print(rawcount_mat.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c344c2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(292495, 96)\n"
     ]
    }
   ],
   "source": [
    "#Get original hpf factorization\n",
    "ds = lp.connect(\"dev_all.loom\")\n",
    "hpf_mat = ds.ca['HPF']\n",
    "ds.close()\n",
    "print(hpf_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6932a35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>ClusterName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e7.0</td>\n",
       "      <td>ParEndo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e7.0</td>\n",
       "      <td>ParEndo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e7.0</td>\n",
       "      <td>ParEndo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e7.0</td>\n",
       "      <td>ParEndo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e7.0</td>\n",
       "      <td>ParEndo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age ClusterName\n",
       "0  e7.0     ParEndo\n",
       "1  e7.0     ParEndo\n",
       "2  e7.0     ParEndo\n",
       "3  e7.0     ParEndo\n",
       "4  e7.0     ParEndo"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.read_csv(data_path+'/metadata.csv',index_col = 0)\n",
    "meta.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b44971dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(277123, 1999)\n",
      "(277123, 1999)\n",
      "(277123, 96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/utils/validation.py:590: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age ClusterName  ClusterID\n",
      "0  e7.0     ParEndo        628\n",
      "1  e7.0     ParEndo        628\n",
      "2  e7.0     ParEndo        628\n",
      "3  e7.0     ParEndo        628\n",
      "4  e7.0     ParEndo        628\n"
     ]
    }
   ],
   "source": [
    "#Filter out nan cells from counts\n",
    "\n",
    "rawcount_mat = rawcount_mat[meta.ClusterName == meta.ClusterName,:]\n",
    "count_mat = count_mat[meta.ClusterName == meta.ClusterName,:]\n",
    "hpf_mat = hpf_mat[meta.ClusterName == meta.ClusterName,:]\n",
    "\n",
    "print(count_mat.shape)\n",
    "print(rawcount_mat.shape)\n",
    "print(hpf_mat.shape)\n",
    "\n",
    "meta = meta[meta.ClusterName == meta.ClusterName]\n",
    "\n",
    "#Center and scale log-normalized data\n",
    "scaled_mat = scale(count_mat)\n",
    "\n",
    "#convert lab1 to ints\n",
    "dNames = {}\n",
    "count = 1\n",
    "for n in np.unique(meta.ClusterName):\n",
    "        dNames[n] = count\n",
    "        count = count + 1\n",
    "\n",
    "meta['ClusterID'] = [dNames[n] for n in list(meta.ClusterName)]\n",
    "print(meta.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae4ed79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchari/.local/lib/python3.7/site-packages/ipykernel_launcher.py:11: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "/home/tchari/.local/lib/python3.7/site-packages/ipykernel_launcher.py:14: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  \n",
      "/home/tchari/.local/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n"
     ]
    }
   ],
   "source": [
    "clusters = np.unique(meta['ClusterName'].values)\n",
    "map_dict = {}\n",
    "for i, c in enumerate(clusters):\n",
    "\tmap_dict[c] = i\n",
    "new_labs = [map_dict[c] for c in meta['ClusterName'].values]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "adata = anndata.AnnData(count_mat, obs = meta)\n",
    "adata.X = np.nan_to_num(adata.X)\n",
    "\n",
    "adata2 = anndata.AnnData(rawcount_mat, obs = meta)\n",
    "adata2.X = np.nan_to_num(adata2.X)\n",
    "\n",
    "adata_hpf = anndata.AnnData(hpf_mat, obs = meta)\n",
    "adata_hpf.X = np.nan_to_num(adata_hpf.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e063331",
   "metadata": {},
   "source": [
    "## **Reduce Spaces and Predict Cell Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87553c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def knn_infer(embd_space, labeled_idx, labeled_lab, unlabeled_idx,n_neighbors=50):\n",
    "\t\"\"\"\n",
    "\tPredicts the labels of unlabeled data in the embedded space with KNN.\n",
    "\tParameters\n",
    "\t----------\n",
    "\tembd_space : ndarray (n_samples, embedding_dim)\n",
    "\t\tEach sample is described by the features in the embedded space.\n",
    "\t\tContains all samples, both labeled and unlabeled.\n",
    "\tlabeled_idx : list\n",
    "\t\tIndices of the labeled samples (used for training the classifier).\n",
    "\tlabeled_lab : ndarray (n_labeled_samples)\n",
    "\t\tLabels of the labeled samples.\n",
    "\tunlabeled_idx : list\n",
    "\t\tIndices of the unlabeled samples.\n",
    "\tReturns\n",
    "\t-------\n",
    "\tpred_lab : ndarray (n_unlabeled_samples)\n",
    "\t\tInferred labels of the unlabeled samples.\n",
    "\t\"\"\"\n",
    "\n",
    "\t# obtain labeled data and unlabled data from indices\n",
    "\tlabeled_samp = embd_space[labeled_idx, :]\n",
    "\tunlabeled_samp = embd_space[unlabeled_idx, :]\n",
    "\n",
    "\tfrom sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\tknn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\tknn.fit(labeled_samp, labeled_lab)\n",
    "\n",
    "\tpred_lab = knn.predict(unlabeled_samp)\n",
    "\treturn pred_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "374b551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copied from https://github.com/linnarsson-lab/cytograph2/blob/master/cytograph/decomposition/HPF.py\n",
    "import logging\n",
    "from typing import Tuple, List, Any\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "from scipy.special import digamma, gammaln, logsumexp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "def _find_redundant_components(factors: np.ndarray, max_r: float) -> List[int]:\n",
    "\tn_factors = factors.shape[1]\n",
    "\t(row, col) = np.where(np.corrcoef(factors.T) > max_r)\n",
    "\tg = sparse.coo_matrix((np.ones(len(row)), (row, col)), shape=(n_factors, n_factors))\n",
    "\t(n_comps, comps) = sparse.csgraph.connected_components(g)\n",
    "\tnon_singleton_comps = np.where(np.bincount(comps) > 1)[0]\n",
    "\tto_randomize: List[int] = []\n",
    "\tfor c in non_singleton_comps:\n",
    "\t\tto_randomize += list(np.where(comps == c)[0][1:])\n",
    "\treturn sorted(to_randomize)\n",
    "\n",
    "\n",
    "def find_redundant_components(beta: np.ndarray, theta: np.ndarray, max_r: float) -> np.ndarray:\n",
    "\t\"\"\"\n",
    "\tFigure out which components are redundant (identical to another factor), and\n",
    "\treturn them as a sorted ndarray. For each set of redundant factors, all but the\n",
    "\tfirst element is returned.\n",
    "\t\"\"\"\n",
    "\treturn np.intersect1d(_find_redundant_components(beta, max_r), _find_redundant_components(theta, max_r))\n",
    "\n",
    "\n",
    "class HPF:\n",
    "\t\"\"\"\n",
    "\tBayesian Hierarchical Poisson Factorization\n",
    "\tImplementation of https://arxiv.org/pdf/1311.1704.pdf\n",
    "\t\"\"\"\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tk: int,\n",
    "\t\t*,\n",
    "\t\ta: float = 0.3,\n",
    "\t\tb: float = 1,\n",
    "\t\tc: float = 0.3,\n",
    "\t\td: float = 1,\n",
    "\t\tmin_iter: int = 10,\n",
    "\t\tmax_iter: int = 100,\n",
    "\t\tstop_interval: int = 10,\n",
    "\t\tepsilon: float = 0.001,\n",
    "\t\tmax_r: float = 0.99,\n",
    "\t\tcompute_X_ppv: bool = True,\n",
    "\t\tvalidation_fraction: float = 0) -> None:\n",
    "\t\t\"\"\"\n",
    "\t\tArgs:\n",
    "\t\t\tk\t\t\t\tNumber of components\n",
    "\t\t\ta\t\t\t\tHyperparameter a in the paper\n",
    "\t\t\tb\t\t\t\tHyperparameter a' in the paper\n",
    "\t\t\tc\t\t\t\tHyperparameter c in the paper\n",
    "\t\t\td\t\t\t\tHyperparameter c' in the paper\n",
    "\t\t\tmax_iter\t\tMaximum number of iterations\n",
    "\t\t\tstop_interval\tInterval between calculating and reporting the log-likelihood\n",
    "\t\t\tepsilon\t\t\tFraction improvement required to continue iterating\n",
    "\t\t\tmax_r\t\t\tMaximum Pearson's correlation coefficient allowed before a component is considered redundant\n",
    "\t\t\tcompute_X_ppv\tIf true, compute the posterior predictive values X_ppv (same shape as X)\n",
    "\t\t\"\"\"\n",
    "\t\tself.k = k\n",
    "\t\tself.a = a\n",
    "\t\tself.b = b\n",
    "\t\tself.c = c\n",
    "\t\tself.d = d\n",
    "\t\tself.min_iter = min_iter\n",
    "\t\tself.max_iter = max_iter\n",
    "\t\tself.stop_interval = stop_interval\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.max_r = max_r\n",
    "\t\tself.compute_X_ppv = compute_X_ppv\n",
    "\t\tself.validation_fraction = validation_fraction\n",
    "\n",
    "\t\tself.beta: np.ndarray = None\n",
    "\t\tself.theta: np.ndarray = None\n",
    "\t\tself.eta: np.ndarray = None\n",
    "\t\tself.xi: np.ndarray = None\n",
    "\t\tself.gamma_shape: np.ndarray = None\n",
    "\t\tself.gamma_rate: np.ndarray = None\n",
    "\t\tself.lambda_shape: np.ndarray = None\n",
    "\t\tself.lambda_rate: np.ndarray = None\n",
    "\t\tself.redundant: np.ndarray = None\n",
    "\t\tself.validation_data: sparse.coo_matrix = None\n",
    "\n",
    "\t\tself.X_ppv: np.ndarray = None\n",
    "\t\tself.log_likelihoods: List[float] = []\n",
    "\n",
    "\t\tself._tau_rate: np.ndarray = None\n",
    "\t\tself._tau_shape: np.ndarray = None\n",
    "\t\tself._lambda_rate: np.ndarray = None\n",
    "\t\tself._lambda_shape: np.ndarray = None\n",
    "\n",
    "\tdef fit(self, X: sparse.coo_matrix) -> Any:\n",
    "\t\t\"\"\"\n",
    "\t\tFit an HPF model to the data matrix\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tX\tData matrix, shape (n_cells, n_genes)\n",
    "\n",
    "\t\tRemarks:\n",
    "\t\t\tAfter fitting, the factor matrices beta and theta are available as self.theta of shape\n",
    "\t\t\t(n_cells, k) and self.beta of shape (k, n_genes)\n",
    "\t\t\"\"\"\n",
    "\t\tif type(X) is not sparse.coo_matrix:\n",
    "\t\t\traise TypeError(\"Input matrix must be in sparse.coo_matrix format\")\n",
    "\n",
    "\t\t(beta, theta, eta, xi, gamma_shape, gamma_rate, lambda_shape, lambda_rate) = self._fit(X)\n",
    "\n",
    "\t\tself.beta = beta\n",
    "\t\tself.theta = theta\n",
    "\t\tself.eta = eta\n",
    "\t\tself.xi = xi\n",
    "\t\tself.gamma_rate = gamma_rate\n",
    "\t\tself.gamma_shape = gamma_shape\n",
    "\t\tself.lambda_rate = lambda_rate\n",
    "\t\tself.lambda_shape = lambda_shape\n",
    "\t\t# Identify redundant components\n",
    "\t\tself.redundant = find_redundant_components(beta, theta, self.max_r)\n",
    "\t\t# Posterior predictive distribution\n",
    "\t\tif self.compute_X_ppv:\n",
    "\t\t\tself.X_ppv = theta @ beta.T\n",
    "\t\treturn self\n",
    "\n",
    "\tdef _fit(self, X: sparse.coo_matrix, beta_precomputed: bool = False) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "\t\t# Create local variables for convenience\n",
    "\t\t(n_users, n_items) = X.shape\n",
    "\t\tk = self.k\n",
    "\t\t(u, i, y) = (X.row, X.col, X.data)  # u and i are indices of the nonzero entries; y are the values of those entries\n",
    "\t\t(a, b, c, d) = (self.a, self.b, self.c, self.d)\n",
    "\t\tlogging.info(f\"nnz={len(u)}\")\n",
    "\n",
    "\t\t# Compute hyperparameters bp and dp\n",
    "\t\tdef mean_var_prior(X: np.ndarray, axis: int) -> float:\n",
    "\t\t\ttemp = X.sum(axis=axis)\n",
    "\t\t\treturn np.mean(temp) / np.var(temp)\n",
    "\t\tbp = b * mean_var_prior(X, axis=1)\n",
    "\t\tdp = d * mean_var_prior(X, axis=0)\n",
    "\n",
    "\t\t# Create the validation dataset\n",
    "\t\tif self.validation_fraction > 0:\n",
    "\t\t\t(u, vu, i, vi, y, vy) = train_test_split(u, i, y, train_size=1 - self.validation_fraction)\n",
    "\t\t\tself.validation_data = sparse.coo_matrix((vy, (vu, vi)), shape=X.shape)\n",
    "\t\telse:\n",
    "\t\t\t(vu, vi, vy) = (u, i, y)\n",
    "\n",
    "\t\t# Initialize the variational parameters with priors and some randomness\n",
    "\t\tkappa_shape = np.full(n_users, b + k * a, dtype='float32')  # This is actually the first variational update, but needed only once\n",
    "\t\tkappa_rate = np.random.uniform(0.5 * bp, 1.5 * bp, n_users).astype('float32')\n",
    "\t\tgamma_shape = np.random.uniform(0.5 * a, 1.5 * a, (n_users, k)).astype('float32')\n",
    "\t\tgamma_rate = np.random.uniform(0.5 * b, 1.5 * b, (n_users, k)).astype('float32')\n",
    "\n",
    "\t\tif beta_precomputed:\n",
    "\t\t\ttau_shape = self._tau_shape\n",
    "\t\t\ttau_rate = self._tau_rate\n",
    "\t\t\tlambda_shape = self._lambda_shape\n",
    "\t\t\tlambda_rate = self._lambda_rate\n",
    "\t\telse:\n",
    "\t\t\ttau_shape = np.full(n_items, d + k * c, dtype='float32')  # This is actually the first variational update, but needed only once\n",
    "\t\t\ttau_rate = np.random.uniform(0.5 * dp, 1.5 * dp, n_items).astype('float32')\n",
    "\t\t\tlambda_shape = np.random.uniform(0.5 * c, 1.5 * c, (n_items, k)).astype('float32')\n",
    "\t\t\tlambda_rate = np.random.uniform(0.5 * d, 1.5 * d, (n_items, k)).astype('float32')\n",
    "\n",
    "\t\tself.log_likelihoods = []\n",
    "\t\twith trange(self.max_iter + 1) as t:\n",
    "\t\t\tt.set_description(f\"HPF.fit(X.shape={X.shape})\")\n",
    "\t\t\tfor n_iter in t:\n",
    "\t\t\t\t# Compute y * phi only for the nonzero values, which are indexed by u and i in the sparse matrix\n",
    "\t\t\t\t# phi is calculated on log scale from expectations of the gammas, hence the digamma and log terms\n",
    "\t\t\t\t# Shape of phi will be (nnz, k)\n",
    "\t\t\t\t# TODO: rewrite in numba so as to calculate each nnz (and sum over k) without materializing the whole phi matrix\n",
    "\t\t\t\t# TODO: maybe parallelize too?\n",
    "\t\t\t\tphi = (digamma(gamma_shape) - np.log(gamma_rate))[u, :] + (digamma(lambda_shape) - np.log(lambda_rate))[i, :]\n",
    "\t\t\t\t# Multiply y by phi normalized (in log space) along the k axis\n",
    "\t\t\t\ty_phi = y[:, None] * np.exp(phi - logsumexp(phi, axis=1)[:, None])\n",
    "\n",
    "\t\t\t\t# Upate the variational parameters corresponding to theta (the users)\n",
    "\t\t\t\t# Sum of y_phi over users, for each k\n",
    "\t\t\t\ty_phi_sum_u = np.zeros((n_users, k))\n",
    "\t\t\t\tfor ix in range(k):\n",
    "\t\t\t\t\ty_phi_sum_u[:, ix] = sparse.coo_matrix((y_phi[:, ix], (u, i)), X.shape).sum(axis=1).A.T[0]\n",
    "\t\t\t\tgamma_shape = a + y_phi_sum_u\n",
    "\t\t\t\tgamma_rate = (kappa_shape / kappa_rate)[:, None] + (lambda_shape / lambda_rate).sum(axis=0)\n",
    "\t\t\t\tkappa_rate = (b / bp) + (gamma_shape / gamma_rate).sum(axis=1)\n",
    "\n",
    "\t\t\t\tif not beta_precomputed:\n",
    "\t\t\t\t\t# Upate the variational parameters corresponding to beta (the items)\n",
    "\t\t\t\t\t# Sum of y_phi over items, for each k\n",
    "\t\t\t\t\ty_phi_sum_i = np.zeros((n_items, k))\n",
    "\t\t\t\t\tfor ix in range(k):\n",
    "\t\t\t\t\t\ty_phi_sum_i[:, ix] = sparse.coo_matrix((y_phi[:, ix], (u, i)), X.shape).sum(axis=0).A\n",
    "\t\t\t\t\tlambda_shape = c + y_phi_sum_i\n",
    "\t\t\t\t\tlambda_rate = (tau_shape / tau_rate)[:, None] + (gamma_shape / gamma_rate).sum(axis=0)\n",
    "\t\t\t\t\ttau_rate = (d / dp) + (lambda_shape / lambda_rate).sum(axis=1)\n",
    "\n",
    "\t\t\t\tif n_iter % self.stop_interval == 0:\n",
    "\t\t\t\t\t# Compute the log likelihood and assess convergence\n",
    "\t\t\t\t\t# Expectations\n",
    "\t\t\t\t\tegamma = gamma_shape / gamma_rate\n",
    "\t\t\t\t\telambda = lambda_shape / lambda_rate\n",
    "\t\t\t\t\t# Sum over k for the expectations\n",
    "\t\t\t\t\t# This is really a dot product but we're only computing it for the nonzeros (indexed by u and i)\n",
    "\t\t\t\t\ts = (egamma[vu] * elambda[vi]).sum(axis=1)\n",
    "\t\t\t\t\t# We use gammaln to compute the log factorial, hence the \"y + 1\"\n",
    "\t\t\t\t\tlog_likelihood = np.sum(vy * np.log(s) - s - gammaln(vy + 1))\n",
    "\t\t\t\t\tself.log_likelihoods.append(log_likelihood)\n",
    "\n",
    "\t\t\t\t\t# Check for convergence\n",
    "\t\t\t\t\t# TODO: allow for small fluctuations\n",
    "\t\t\t\t\tif len(self.log_likelihoods) > 1:\n",
    "\t\t\t\t\t\tprev_ll = self.log_likelihoods[-2]\n",
    "\t\t\t\t\t\tdiff = (log_likelihood - prev_ll) / abs(prev_ll)\n",
    "\t\t\t\t\t\tt.set_postfix(ll=log_likelihood, diff=diff)\n",
    "\t\t\t\t\t\tif diff < self.epsilon and n_iter >= self.min_iter:\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tt.set_postfix(ll=log_likelihood)\n",
    "\n",
    "\t\t# End of the main fitting loop\n",
    "\t\tif not beta_precomputed:\n",
    "\t\t\t# Save these for future use in self.transform()\n",
    "\t\t\tself._tau_shape = tau_shape\n",
    "\t\t\tself._tau_rate = tau_rate\n",
    "\t\t\tself._lambda_shape = lambda_shape\n",
    "\t\t\tself._lambda_rate = lambda_rate\n",
    "\n",
    "\t\t# Compute beta and theta, which are given by the expectations, i.e. shape / rate\n",
    "\t\tbeta = lambda_shape / lambda_rate\n",
    "\t\ttheta = gamma_shape / gamma_rate\n",
    "\t\teta = tau_shape / tau_rate\n",
    "\t\txi = kappa_shape / kappa_rate\n",
    "\t\treturn (beta, theta, eta, xi, gamma_shape, gamma_rate, lambda_shape, lambda_rate)\n",
    "\n",
    "\tdef transform(self, X: sparse.coo_matrix) -> np.ndarray:\n",
    "\t\t\"\"\"\n",
    "\t\tTransform the data matrix using an already fitted HPF model\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tX      Data matrix, shape (n_cells, n_genes)\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t\tFactor matrix theta of shape (n_cells, k)\n",
    "\t\t\"\"\"\n",
    "\t\tif type(X) is not sparse.coo_matrix:\n",
    "\t\t\traise TypeError(\"Input matrix must be in sparse.coo_matrix format\")\n",
    "\n",
    "\t\t(_, theta, _, _, _, _, _, _) = self._fit(X, beta_precomputed=True)\n",
    "\n",
    "\t\treturn theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce319094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPF.fit(X.shape=(277123, 1999)):  89%|████████████████████████████████████████████████      | 90/101 [1:23:33<10:12, 55.70s/it, diff=0.000802, ll=-8.46e+7]\n",
      "HPF.fit(X.shape=(277123, 1999)):  30%|████████████████▋                                       | 30/101 [18:32<43:52, 37.08s/it, diff=0.000598, ll=-8.42e+7]\n"
     ]
    }
   ],
   "source": [
    "#2D embeddings From HPF 30 --> 2D\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "#Get HPF 30D factorization, as in paper\n",
    "h_reduce = HPF(k=30)\n",
    "h_reduce.fit(coo_matrix(rawcount_mat))\n",
    "hpf30 = h_reduce.transform(coo_matrix(rawcount_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70222473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save mat\n",
    "np.save('hpf30.npy',hpf30)\n",
    "# hpf30 = np.load('hpf30.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4b01d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab1 = list(meta.ClusterName)\n",
    "lab2 = list(meta.Age)\n",
    "# lab3 = list(meta.medical_cond_label)\n",
    "lab4 = list(meta.ClusterID)\n",
    "\n",
    "\n",
    "allLabs = np.array([lab1])\n",
    "allLabs2 = np.array([lab1,lab2])\n",
    "\n",
    "nanLabs = np.array([[np.nan]*len(lab1)])\n",
    "\n",
    "#Shuffled labels for over-fitting check\n",
    "shuff_lab1 = random.sample(lab1, len(lab1))  \n",
    "shuff_lab2 = random.sample(lab2, len(lab2))  \n",
    "shuff_allLabs = np.array([shuff_lab1,shuff_lab2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb8ba45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "948439d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n",
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n",
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.407219408927433, 0.38957383595751593, 0.43360958418032886, 0.4101663519251356, 0.39545569361415495, 0.4359551102397248, 0.4029132636491574, 0.3923403538737265, 0.43270745877286887]\n"
     ]
    }
   ],
   "source": [
    "#2D embeddings, from PCA50D --> 2D\n",
    "ndims = 2\n",
    "acc_score_2D = []\n",
    "\n",
    "for i in range(3):\n",
    "\treducer = umap.UMAP(n_components = ndims)\n",
    "\ttsne = TSNE(n_components = ndims) \n",
    "\n",
    "\n",
    "\ttsvd = TruncatedSVD(n_components=pcs)\n",
    "\tx_pca = tsvd.fit_transform(scaled_mat)\n",
    "\n",
    "\tpcaUMAP = reducer.fit_transform(x_pca)\n",
    "\tpcaTSNE = tsne.fit_transform(x_pca)\n",
    "\n",
    "\t#Partially labeled UMAP\n",
    "\n",
    "\tlabels = np.array([lab4]).copy().astype(np.int8)\n",
    "\ttrain_inds = np.random.choice(len(scaled_mat), size = int(0.7*len(scaled_mat)),replace=False) #0.7 for training fraction\n",
    "\t#Set 30% to no label (nan)\n",
    "\tunlab_inds = [i for i in range(len(adata)) if i not in train_inds]\n",
    "\tlabels[:, unlab_inds] = -1\n",
    "\n",
    "\tpcaUMAPLab = reducer.fit_transform(x_pca,y=labels[0])\n",
    "\n",
    "\tpreds = knn_infer(pcaUMAPLab, train_inds, adata.obs.ClusterID.values[train_inds], unlab_inds)\n",
    "\tacc = accuracy_score(adata.obs.ClusterID.values[unlab_inds], preds)\n",
    "\tacc_score_2D.append(acc)\n",
    "\n",
    "\n",
    "\n",
    "\tpreds = knn_infer(pcaUMAP, train_inds, adata.obs.ClusterID.values[train_inds], unlab_inds)\n",
    "\tacc = accuracy_score(adata.obs.ClusterID.values[unlab_inds], preds)\n",
    "\tacc_score_2D.append(acc)\n",
    "\n",
    "\tpreds = knn_infer(pcaTSNE, train_inds, adata.obs.ClusterID.values[train_inds], unlab_inds)\n",
    "\tacc = accuracy_score(adata.obs.ClusterID.values[unlab_inds], preds)\n",
    "\tacc_score_2D.append(acc)\n",
    "\n",
    "print(acc_score_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9744baf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n",
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n",
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2771569818492368, 0.26763053754645943, 0.295800906936743, 0.27851618412980983, 0.27044516881773456, 0.295800906936743, 0.275003909210099, 0.270938330707146, 0.29568062354908164]\n"
     ]
    }
   ],
   "source": [
    "#2D embeddings From HPF 96 --> 2D\n",
    "ndims = 2\n",
    "acc_score_96_2D = []\n",
    "\n",
    "for i in range(3):\n",
    "\treducer = umap.UMAP(n_components = ndims)\n",
    "\ttsne = TSNE(n_components = ndims,early_exaggeration = 1.5, perplexity = 150)  #From paper\n",
    "\n",
    "\tx_pca = hpf_mat\n",
    "\n",
    "\tpcaUMAP = reducer.fit_transform(x_pca)\n",
    "\tpcaTSNE = tsne.fit_transform(x_pca)\n",
    "\n",
    "\t#Partially labeled UMAP\n",
    "\n",
    "\tlabels = np.array([lab4]).copy().astype(np.int8)\n",
    "\ttrain_inds = np.random.choice(len(scaled_mat), size = int(0.7*len(scaled_mat)),replace=False) #0.7 for training fraction\n",
    "\t#Set 30% to no label (nan)\n",
    "\tunlab_inds = [i for i in range(len(adata)) if i not in train_inds]\n",
    "\tlabels[:, unlab_inds] = -1\n",
    "\n",
    "\tpcaUMAPLab = reducer.fit_transform(x_pca,y=labels[0])\n",
    "\n",
    "\tpreds = knn_infer(pcaUMAPLab, train_inds, adata.obs.ClusterID.values[train_inds], unlab_inds)\n",
    "\tacc = accuracy_score(adata.obs.ClusterID.values[unlab_inds], preds)\n",
    "\tacc_score_96_2D.append(acc)\n",
    "\n",
    "\n",
    "\n",
    "\tpreds = knn_infer(pcaUMAP, train_inds, adata.obs.ClusterID.values[train_inds], unlab_inds)\n",
    "\tacc = accuracy_score(adata.obs.ClusterID.values[unlab_inds], preds)\n",
    "\tacc_score_96_2D.append(acc)\n",
    "\n",
    "\tpreds = knn_infer(pcaTSNE, train_inds, adata.obs.ClusterID.values[train_inds], unlab_inds)\n",
    "\tacc = accuracy_score(adata.obs.ClusterID.values[unlab_inds], preds)\n",
    "\tacc_score_96_2D.append(acc)\n",
    "\n",
    "print(acc_score_96_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84e94466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n",
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n",
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "/home/tchari/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.234492464245763, 0.23373467890349664, 0.2516929886813332, 0.23533444795939232, 0.22579597531784884, 0.2505984098536151, 0.23752360561482855, 0.2300058938859954, 0.2524387456848335]\n"
     ]
    }
   ],
   "source": [
    "#2D embeddings From HPF 30 --> 2D\n",
    "ndims = 2\n",
    "acc_score_30_2D = []\n",
    "\n",
    "for i in range(3):\n",
    "\treducer = umap.UMAP(n_components = ndims) \n",
    "\ttsne = TSNE(n_components = ndims,early_exaggeration = 1.5, perplexity = 150) #from paper\n",
    "\n",
    "\tx_pca = hpf30\n",
    "\n",
    "\tpcaUMAP = reducer.fit_transform(x_pca)\n",
    "\tpcaTSNE = tsne.fit_transform(x_pca)\n",
    "\n",
    "\t#Partially labeled UMAP\n",
    "\n",
    "\tlabels = np.array([lab4]).copy().astype(np.int8)\n",
    "\ttrain_inds = np.random.choice(len(scaled_mat), size = int(0.7*len(scaled_mat)),replace=False) #0.7 for training fraction\n",
    "\t#Set 30% to no label (nan)\n",
    "\tunlab_inds = [i for i in range(len(adata)) if i not in train_inds]\n",
    "\tlabels[:, unlab_inds] = -1\n",
    "\n",
    "\tpcaUMAPLab = reducer.fit_transform(x_pca,y=labels[0])\n",
    "\n",
    "\tpreds = knn_infer(pcaUMAPLab, train_inds, adata.obs.ClusterID.values[train_inds], unlab_inds)\n",
    "\tacc = accuracy_score(adata.obs.ClusterID.values[unlab_inds], preds)\n",
    "\tacc_score_30_2D.append(acc)\n",
    "\n",
    "\n",
    "\n",
    "\tpreds = knn_infer(pcaUMAP, train_inds, adata.obs.ClusterID.values[train_inds], unlab_inds)\n",
    "\tacc = accuracy_score(adata.obs.ClusterID.values[unlab_inds], preds)\n",
    "\tacc_score_30_2D.append(acc)\n",
    "\n",
    "\tpreds = knn_infer(pcaTSNE, train_inds, adata.obs.ClusterID.values[train_inds], unlab_inds)\n",
    "\tacc = accuracy_score(adata.obs.ClusterID.values[unlab_inds], preds)\n",
    "\tacc_score_30_2D.append(acc)\n",
    "\n",
    "print(acc_score_30_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5971c632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efcc05a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5040595643335699, 0.5031814956036422, 0.5024838519552065]\n",
      "[0.5412872728147515, 0.5413714711861145, 0.5385327832373071]\n"
     ]
    }
   ],
   "source": [
    "# #PCA 50D accuracy\n",
    "acc_scorePCA = []\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "\ttsvd = TruncatedSVD(n_components=pcs)\n",
    "\tx_pca = tsvd.fit_transform(scaled_mat)\n",
    "\n",
    "\tlabels = np.array([lab1])\n",
    "\ttrain_inds = np.random.choice(len(scaled_mat), size = int(0.7*len(scaled_mat)),replace=False)\n",
    "\tunlab_inds = [i for i in range(len(adata)) if i not in train_inds]\n",
    "\tlabels[:, unlab_inds] = np.nan\n",
    "\n",
    "\tunlabeled_idx = []\n",
    "\tfor i in range(len(adata)):\n",
    "\t\tif i not in train_inds:\n",
    "\t\t\tunlabeled_idx.append(i)\n",
    "\n",
    "\tpreds = knn_infer(x_pca, train_inds, adata.obs.ClusterName.values[train_inds], unlabeled_idx)\n",
    "\tacc = accuracy_score(adata.obs.ClusterName.values[unlabeled_idx], preds)\n",
    "\tacc_scorePCA.append(acc)\n",
    "\n",
    "print(acc_scorePCA)\n",
    "\n",
    "#Larger PCA reduction (100D)\n",
    "acc_scorePCA2 = []\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "\ttsvd = TruncatedSVD(n_components=pcs2)\n",
    "\tx_pca = tsvd.fit_transform(scaled_mat)\n",
    "\n",
    "\tlabels = np.array([lab1])\n",
    "\ttrain_inds = np.random.choice(len(scaled_mat), size = int(0.7*len(scaled_mat)),replace=False)\n",
    "\tunlab_inds = [i for i in range(len(adata)) if i not in train_inds]\n",
    "\tlabels[:, unlab_inds] = np.nan\n",
    "\n",
    "\tunlabeled_idx = []\n",
    "\tfor i in range(len(adata)):\n",
    "\t\tif i not in train_inds:\n",
    "\t\t\tunlabeled_idx.append(i)\n",
    "\n",
    "\tpreds = knn_infer(x_pca, train_inds, adata.obs.ClusterName.values[train_inds], unlabeled_idx)\n",
    "\tacc = accuracy_score(adata.obs.ClusterName.values[unlabeled_idx], preds)\n",
    "\tacc_scorePCA2.append(acc)\n",
    "\n",
    "print(acc_scorePCA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2ab1c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3811179138049244, 0.386963686445265, 0.383884431721135]\n"
     ]
    }
   ],
   "source": [
    "#HPF 96\n",
    "acc_score_hpf96 = []\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "\tx_pca = hpf_mat\n",
    "\n",
    "\tlabels = np.array([lab1])\n",
    "\ttrain_inds = np.random.choice(len(scaled_mat), size = int(0.7*len(scaled_mat)),replace=False)\n",
    "\tunlab_inds = [i for i in range(len(adata)) if i not in train_inds]\n",
    "\tlabels[:, unlab_inds] = np.nan\n",
    "\n",
    "\tunlabeled_idx = []\n",
    "\tfor i in range(len(adata)):\n",
    "\t\tif i not in train_inds:\n",
    "\t\t\tunlabeled_idx.append(i)\n",
    "\n",
    "\tpreds = knn_infer(x_pca, train_inds, adata.obs.ClusterName.values[train_inds], unlabeled_idx)\n",
    "\tacc = accuracy_score(adata.obs.ClusterName.values[unlabeled_idx], preds)\n",
    "\tacc_score_hpf96.append(acc)\n",
    "\n",
    "print(acc_score_hpf96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "660c01e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3219866004306145, 0.3208799932641303, 0.3219986287693807]\n"
     ]
    }
   ],
   "source": [
    "#HPF 30\n",
    "acc_score_hpf30 = []\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "\tx_pca = hpf30\n",
    "\n",
    "\tlabels = np.array([lab1])\n",
    "\ttrain_inds = np.random.choice(len(scaled_mat), size = int(0.7*len(scaled_mat)),replace=False)\n",
    "\tunlab_inds = [i for i in range(len(adata)) if i not in train_inds]\n",
    "\tlabels[:, unlab_inds] = np.nan\n",
    "\n",
    "\tunlabeled_idx = []\n",
    "\tfor i in range(len(adata)):\n",
    "\t\tif i not in train_inds:\n",
    "\t\t\tunlabeled_idx.append(i)\n",
    "\n",
    "\tpreds = knn_infer(x_pca, train_inds, adata.obs.ClusterName.values[train_inds], unlabeled_idx)\n",
    "\tacc = accuracy_score(adata.obs.ClusterName.values[unlabeled_idx], preds)\n",
    "\tacc_score_hpf30.append(acc)\n",
    "\n",
    "print(acc_score_hpf30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c966a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f02bdaa8",
   "metadata": {},
   "source": [
    "## **Save Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d897a449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs\n"
     ]
    }
   ],
   "source": [
    "#---------------- Save knn prediction accuracy scores for cell type labels ----------------\n",
    "vals = pd.DataFrame()\n",
    "\n",
    "vals['Accuracy'] = acc_scorePCA  + acc_scorePCA2 + acc_score_2D +  acc_score_96_2D + acc_score_30_2D + acc_score_hpf96 + acc_score_hpf30 #acc_score  +  acc_score_scanvi + acc_scoreR + acc_scoreBoth + \n",
    "\n",
    "r = 3\n",
    "vals['Embed'] = ['PCA 50D']*r +['PCA 100D']*r + ['PCA UMAP Sup.','PCA UMAP','PCA t-SNE']*r + ['HPF96 UMAP Sup.','HPF96 UMAP','HPF96 t-SNE']*r +['HPF30 UMAP Sup.','HPF30 UMAP','HPF30 t-SNE']*r + ['HPF 96D']*r + ['HPF 30D']*r #  ['LDVAE']*r + ['SCANVI']*r + ['Recon MCML']*r + ['NCA-Recon MCML']*r +\n",
    "\n",
    "\n",
    "# vals['Label'] = ['CellType1']*15 #+ ['Gender2']*12 + ['CellType2']*1 #+  ['CellType1'] #+  ['Gender2']\n",
    "vals.to_csv('allLaMannoPreds052323.csv')  #allLaMannoPreds103122.csv\n",
    "print('Saved outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49cfcdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
